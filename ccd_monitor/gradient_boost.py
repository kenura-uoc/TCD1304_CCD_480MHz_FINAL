import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.ensemble import GradientBoostingRegressor
from sklearn.model_selection import cross_val_predict, KFold
from sklearn.metrics import mean_squared_error, r2_score
try:
    import emlearn
except ImportError:
    emlearn = None

# 1. Load Data
print("Loading data for Gradient Boosting...")
df = pd.read_csv('ccd_features.csv')

# Define features for training (exclude metadata)
drop_cols = ['concentration_mg_L', 'project', 'filename', 'target_pigment', 'sample_number']
feature_cols = [c for c in df.columns if c not in drop_cols]
print(f"Total Samples: {len(df)}")

# ============================================================
# MULTI-RANGE MODEL STRATEGY (CROSS-VALIDATED)
# ============================================================
ranges = {
    "HIGH_CONC":  (df['integration_time_ms'] < 500),
    "MID_CONC":   ((df['integration_time_ms'] >= 500) & (df['integration_time_ms'] <= 1500)),
    "LOW_CONC":   (df['integration_time_ms'] > 1500)
}

final_models = {}
cv_results = []

print("\n" + "="*80)
print("TRAINING GRADIENT BOOSTING MODELS (5-FOLD CV)")
print("="*80)

for range_name, mask in ranges.items():
    subset = df[mask].copy()
    if len(subset) < 5:
        print(f"Skipping {range_name}: Not enough samples ({len(subset)})")
        continue

    print(f"\nProcessing {range_name} Range ({len(subset)} samples)...")
    
    X = subset[feature_cols].select_dtypes(include=[np.number])
    y = subset['concentration_mg_L']
    
    # Cross-Validation
    n_splits = min(5, len(subset))
    kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)
    
    gb_model = GradientBoostingRegressor(n_estimators=100, random_state=42)
    y_pred_gb = cross_val_predict(gb_model, X, y, cv=kf)
    
    mse_cv = mean_squared_error(y, y_pred_gb)
    r2_cv = r2_score(y, y_pred_gb)
    
    print(f"  -> Cross-Validated R²: {r2_cv:.4f}")
    print(f"  -> Cross-Validated MSE: {mse_cv:.4f}")
    
    # Store CV predictions
    for idx, (actual, pred) in enumerate(zip(y, y_pred_gb)):
        cv_results.append({
            'Actual_Conc': actual,
            'Predicted': pred,
            'Int_Time': subset.iloc[idx]['integration_time_ms'],
            'Model_Used': range_name
        })

    # Train Final Model
    final_model = GradientBoostingRegressor(n_estimators=100, random_state=42)
    final_model.fit(X, y)
    final_models[range_name] = final_model
    print(f"  -> Final Model (GBT) trained on all {len(subset)} samples.")

# ==============================================================================
# 3. Export to C Code for STM32
# ==============================================================================
if emlearn is None:
    print("\n[NOTE] 'emlearn' library not installed. Skipping C code generation.")
else:
    print("\nExporting models to C header (stm32_gb_model.h)...")
    c_header = """#ifndef STM32_GB_MODEL_H
#define STM32_GB_MODEL_H

// Auto-generated by gradient_boost.py using emlearn
"""
    for name, model in final_models.items():
        c_model = emlearn.convert(model)
        filename = f"gb_model_{name.lower()}.h"
        c_model.save(file=filename, name=f"model_{name.lower()}")
        print(f"  Saved {filename}")
        c_header += f'#include "{filename}"\\n'

    c_header += "\\n#endif // STM32_GB_MODEL_H\\n"

    with open("stm32_gb_model.h", "w") as f:
        f.write(c_header)

    print("Master header saved to stm32_gb_model.h")

# ============================================================
# RESULTS & VISUALIZATION
# ============================================================
sim_df = pd.DataFrame(cv_results)
mse = mean_squared_error(sim_df['Actual_Conc'], sim_df['Predicted'])
r2 = r2_score(sim_df['Actual_Conc'], sim_df['Predicted'])

print("\n" + "="*80)
print(f"OVERALL PERFORMANCE (GBT)")
print("="*80)
print(f"  RMSE: {np.sqrt(mse):.4f}")
print(f"  R²:   {r2:.4f}")

plt.figure(figsize=(10, 6))
sc = plt.scatter(sim_df['Actual_Conc'], sim_df['Predicted'], 
                 c=sim_df['Int_Time'], cmap='viridis', 
                 alpha=0.8, edgecolor='k', s=60)
cbar = plt.colorbar(sc)
cbar.set_label('Integration Time (ms)')
plt.plot([0, sim_df['Actual_Conc'].max()], [0, sim_df['Actual_Conc'].max()], 'k--', alpha=0.5)
plt.xlabel('Actual Concentration (mg/L)')
plt.ylabel('Predicted Concentration (mg/L) [GBT]')
plt.title(f'Gradient Boosting Performance (R²={r2:.3f})')
plt.grid(True)
plt.savefig('gbt_performance.png')
print("\nSaved plot to gbt_performance.png")
